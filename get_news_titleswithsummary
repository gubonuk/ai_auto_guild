"""
작성자: 김혜성

입력 : 링크
출력 : 제목, 내용요약본
"""





import requests
from bs4 import BeautifulSoup
from collections import Counter
import re
import heapq


def get_news_article(url: str) -> tuple:
    """주어진 뉴스 기사 URL에서 제목과 본문 텍스트를 추출하는 함수"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36"
    }

    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # HTTP 요청이 성공했는지 확인
    except requests.RequestException as e:
        print(f"Error fetching the URL: {e}")
        return "", ""

    soup = BeautifulSoup(response.text, "html.parser")

    # 제목 추출
    title_tag = soup.select_one(
        "body > div:nth-of-type(1) > main > div:nth-of-type(1) > div:nth-of-type(5) > div > div > strong")
    title = title_tag.get_text(strip=True) if title_tag else "제목을 찾을 수 없습니다."

    # 본문 추출
    article_div = soup.select_one(
        "body > div:nth-of-type(1) > main > div:nth-of-type(1) > div:nth-of-type(6) > div:nth-of-type(1) > div:nth-of-type(1)")
    article_text = article_div.get_text(separator="\n", strip=True) if article_div else "기사 본문을 찾을 수 없습니다."

    return title, article_text


def summarize_text(text: str, num_sentences: int = 3) -> str:
    """주어진 텍스트를 num_sentences 개의 문장으로 요약 (TextRank 기반)"""
    sentences = re.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|!)\s', text)
    word_frequencies = Counter(re.findall(r'\b\w+\b', text.lower()))
    max_freq = max(word_frequencies.values(), default=1)
    word_frequencies = {word: freq / max_freq for word, freq in word_frequencies.items()}
    sentence_scores = {sent: sum(word_frequencies.get(word, 0) for word in sent.lower().split()) for sent in sentences}
    summary_sentences = heapq.nlargest(num_sentences, sentence_scores, key=sentence_scores.get)
    return "\n".join(summary_sentences)


if __name__ == "__main__":
    test_url = "https://www.yonhapnewstv.co.kr/news/AKR20250224111000325"
    title, article = get_news_article(test_url)
    if article and article != "기사 본문을 찾을 수 없습니다.":
        summary = summarize_text(article, 3)
        print(f"제목: {title}\n")
        print("[요약된 기사]")
        print(summary)
    else:
        print("기사 본문을 찾을 수 없습니다.")
